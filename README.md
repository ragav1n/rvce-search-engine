# ğŸ” RVCE Site-Wide Search Engine

A fast, full-text search engine built for RVCE's official website. It crawls HTML pages and PDFs using Scrapy, indexes content into Elasticsearch, and exposes a powerful search API using FastAPI.

---

## ğŸš€ Features

- ğŸ”— Crawls all internal links and PDFs from the RVCE website.
- ğŸ“„ Extracts and stores titles, content, and URLs.
- âš¡ Indexes 7000+ pages into Elasticsearch.
- ğŸ§  Fuzzy search with highlighting via FastAPI.
- ğŸŒ API-ready backend for integration into any frontend.
- ğŸŒ™ Dark-mode React frontend with keyboard-powered search (â†µ Enter).

---

## ğŸ—‚ï¸ Project Structure

```

rvce-search-engine/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ elastic_client.py 
â”‚   â””â”€â”€ main.py               # FastAPI backend exposing /search endpoint
â”‚   â””â”€â”€ requirements.txt 
â”œâ”€â”€ frontend/
â”œâ”€â”€ crawler/
â”‚   â””â”€â”€ scrapy.cfg
â”‚   â””â”€â”€ crawler/         # Scrapy spider that crawls and dumps data
â”‚       â””â”€â”€ spiders
â”‚           â””â”€â”€ __init__.py
â”‚           â””â”€â”€ rvce_spider.py
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ items.py
â”‚       â”œâ”€â”€ middlewares.py
â”‚       â”œâ”€â”€ pipelines.py
â”‚       â”œâ”€â”€ settings.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ rvce_pages.json
â”‚   â””â”€â”€ rvce_pages_with_pdfs.json   # Output of crawler (HTML + PDFs)
â”œâ”€â”€ indexer/
â”‚   â””â”€â”€ elastic_indexer.py    # Indexes data into Elasticsearch
â”œâ”€â”€ pdf_parser/
â”‚   â””â”€â”€ extract_text.py
â”œâ”€â”€ requirements.txt          # Python dependencies (backend + crawler)
â””â”€â”€ README.md

````

---

## âš™ï¸ Requirements

- Python 3.9+
- Docker
- Elasticsearch 8.x or 9.x
- pip (Python package manager)

---

## ğŸ“¦ Setup Instructions

### 1. Install Dependencies

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
````

### 2. Start Elasticsearch (via Docker)

```bash
docker run -d -p 9200:9200 \
  -e "discovery.type=single-node" \
  -e "xpack.security.enabled=false" \
  elasticsearch:9.1.0
```

> âœ… You can also use `elasticsearch:8.12.0` if preferred (ensure Python client version matches).

### 3. Run the Scrapy Crawler

```bash
cd crawler
scrapy crawl rvce
```

This will crawl `rvce.edu.in` and extract structured page + PDF data into a JSON file.

### 4. Extract Text from PDFs

```bash
python pdf_parser/extract_text.py 
```

This extracts text from pdfs and merge into a clean format.

### 5. Index Data into Elasticsearch

```bash
python indexer/elastic_indexer.py
```

This loads the data file and populates the Elasticsearch index (`rvce`).


### 6. Run the FastAPI Backend

```bash
cd backend
uvicorn main:app --reload --port 8000
```

You can now access the search API at:

```
GET http://localhost:8000/search?q=your_query
```

### 7. Run the Frontend

```bash
npm install

npm run dev
```
You can now access the simple frontend with the Search feature.

---

## ğŸ§ª Example API Query

```bash
curl "http://localhost:8000/search?query=admissions"
```

Returns:

```json
{
  "query": "admissions",
  "total": 10,
  "results": [
    {
      "title": "Online Fee Payment | R V College of Engineering",
      "url": "https://rvce.edu.in/Online-Fee-Payment",
      "score": 0.83,
      "snippet": "...Admissions open for..."
    }
  ]
}
```

---

## ğŸŒ Frontend

A dark-mode React + Vite-based frontend is available in the `frontend/` folder. It uses `fetch` to call the `/search` API.

---

## ğŸ“Œ Notes

* The current project runs completely offline using crawled data.
* You can re-run the spider anytime to update the dataset.
* Fuzzy deduplication and scoring enhancements are included in the backend.

---

## ğŸ™‹â€â™‚ï¸ Maintainer

Built by Ragav

---
